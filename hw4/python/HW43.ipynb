{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW43.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "CmO1WEDPp1xy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sd_AEJspQJg",
        "colab_type": "code",
        "outputId": "59acd0c5-5424-46cd-f3d5-8b5f415e7330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the colors dataset\n",
        "if not os.path.exists('colors.csv'):\n",
        "  !curl -O 'https://raw.githubusercontent.com/random-forests/datasets/master/colors.csv'\n",
        "!head colors.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name,red,green,blue\n",
            "parakeet,174,182,87\n",
            "saddle brown,88,52,1\n",
            "cucumber crush,222,237,215\n",
            "pool blue,134,194,201\n",
            "distance,98,110,130\n",
            "light urple,179,111,246\n",
            "east side,172,145,206\n",
            "florida seashells,250,228,199\n",
            "paris,145,167,189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mG0WnNZtmxul",
        "colab_type": "code",
        "outputId": "e3bfc426-3f88-43e1-b7f5-66379daa71a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "colors_rgb = []\n",
        "csv_reader = csv.reader(open('colors.csv'), delimiter=',')\n",
        "next(csv_reader) # Remove the header\n",
        "for row in csv_reader:\n",
        "    name, r, g, b = row[0].lower().strip(), int(row[1]), int(row[2]), int(row[3])\n",
        "    colors_rgb.append((name, r, g, b))\n",
        "print(len(colors_rgb), 'colors downloaded')\n",
        "print('For example', colors_rgb[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14157 colors downloaded\n",
            "For example ('parakeet', 174, 182, 87)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PdIWQdlBrZXA",
        "colab_type": "code",
        "outputId": "529bb6c3-398b-452a-d4e1-b3d47a5fa92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# In this experiment, we will train a char-baed RNN to generate a line of text\n",
        "# that resembles this dataset (we'll treat each line as a string)\n",
        "sentences = []\n",
        "for row in colors_rgb:\n",
        "  line = ' '.join([str(part) for part in row])\n",
        "  sentences.append(line)\n",
        "print(sentences[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parakeet 174 182 87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_o2oIUNuyWZ",
        "colab_type": "code",
        "outputId": "d000fd8d-09da-4fb6-c9d2-37aafed901fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# vocabulary for our char-based RNN\n",
        "chars = set()\n",
        "for sentence in sentences:\n",
        "  for char in sentence:\n",
        "    chars.add(char)\n",
        "    \n",
        "# add a special char for padding\n",
        "chars.add('<pad>')\n",
        "\n",
        "vocab = sorted(set(chars))\n",
        "\n",
        "# Create a mapping from unique characters to indices\n",
        "char2idx = {u : i for i, u in enumerate(vocab)}\n",
        "idx2char = {i : u for i, u in enumerate(vocab)}\n",
        "\n",
        "# Vocab size\n",
        "vocab_size = len(vocab)\n",
        "print('vocab size:', vocab_size)\n",
        "print(vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 38\n",
            "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '<pad>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5sdKRJ6rp8I",
        "colab_type": "code",
        "outputId": "2225d89c-d24f-4678-8929-544257448997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# vectorize the text\n",
        "text_int = []\n",
        "for sentence in sentences:\n",
        "  int_sentence = [] \n",
        "  for c in sentence:\n",
        "    int_sentence.append(char2idx[c])\n",
        "  text_int.append(int_sentence)\n",
        "print('Vectorized sentence', text_int[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorized sentence [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0g6Do15As4yQ",
        "colab_type": "code",
        "outputId": "43857498-ca02-407c-f60b-c8981fa01b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# pad sentences to max_length\n",
        "max_length = 40\n",
        "for sentence in text_int:\n",
        "  while (len(sentence) < max_length):\n",
        "    sentence.append(char2idx['<pad>'])\n",
        "print('Padded sentences', text_int[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padded sentences [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-y87WF_Fw1kJ",
        "colab_type": "code",
        "outputId": "3ffdbc0f-03d4-4a6e-e75d-85bd7398103b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# truncate all sentences to max_length\n",
        "for i in range(len(text_int)):\n",
        "  sentence = text_int[i]\n",
        "  if len(sentence) > max_length:\n",
        "    text_int[i] = sentence[:max_length]\n",
        "print(\"Truncated sentences\", text_int[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncated sentences [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mwu3FgSpxNWT",
        "colab_type": "code",
        "outputId": "a2682ac4-f22d-48cc-abfc-00dea84a8593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# Create training examples / targets\n",
        "input_text = []\n",
        "target_text = []\n",
        "\n",
        "for i in range(len(text_int)):\n",
        "  inps = text_int[i][:max_length-1]\n",
        "  targ = text_int[i][1:max_length]\n",
        "  input_text.append(inps)\n",
        "  target_text.append(targ)\n",
        "  \n",
        "print(\"First training example, target\")  \n",
        "print(input_text[0])\n",
        "print(target_text[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First training example, target\n",
            "[27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
            "[12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cjyeDrvGzl8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TT8ed7cu0w-z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, units):\n",
        "    super(Model, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.LSTM = tf.keras.layers.LSTM(32, return_sequences = True)\n",
        "    self.dense1 = tf.keras.layers.Dense(128)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "    self.dense2 = tf.keras.layers.Dense(128)\n",
        "    self.batch = tf.keras.layers.BatchNormalization()\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "  def call(self, x):\n",
        "    embedding = self.embedding(x)\n",
        "    lstm = self.LSTM(embedding)\n",
        "    dense1 = self.dense1(lstm)\n",
        "    dropout = self.dropout(dense1)\n",
        "    dense2 = self.dense2(dropout)\n",
        "    batch = self.batch(dense2)\n",
        "    prediction = self.fc(dense2)\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jA8Pssrh1NKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4df80d51-7fb7-4f70-d15a-c10ce5c57954"
      },
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension \n",
        "# Here, this is basically just a trick to avoid having \n",
        "# to one-hot encode the characters\n",
        "# I don't think it will add much otherwise\n",
        "# this would be more useful if we had a much larger vocabulary\n",
        "embedding_dim = 128\n",
        "\n",
        "# Number of RNN units\n",
        "units = 256\n",
        "\n",
        "model = Model(vocab_size, embedding_dim, units)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.LSTM object at 0x7f109b115b70>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FrSRbSQk1Rcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "# Using sparse_softmax_cross_entropy so that we don't have to create one-hot vectors\n",
        "def loss_function(labels, logits):\n",
        "    return tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AILeTt71UXr",
        "colab_type": "code",
        "outputId": "1ae4ce7a-82ca-4727-93ee-6cd1505089be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "model.build(tf.TensorShape([BATCH_SIZE, max_length]))\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  4864      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  20608     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  4224      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo multiple                  512       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  4902      \n",
            "=================================================================\n",
            "Total params: 51,622\n",
            "Trainable params: 51,366\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gjYtdulr8ukK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# Checkpoint instance\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GkLMi8GI1c9b",
        "colab_type": "code",
        "outputId": "1f055394-ee01-4773-84e6-38f821335d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    # initializing the hidden state at the start of every epoch\n",
        "    # initally hidden is None\n",
        "    hidden = model.reset_states()\n",
        "    \n",
        "    for (batch, (input_seq, target_seq)) in enumerate(dataset):\n",
        "          with tf.GradientTape() as tape:\n",
        "              predictions = model(input_seq)\n",
        "              loss = loss_function(target_seq, predictions)\n",
        "              \n",
        "          grads = tape.gradient(loss, model.variables)\n",
        "          optimizer.apply_gradients(zip(grads, model.variables))\n",
        "\n",
        "          if batch % 100 == 0:\n",
        "              print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n",
        "                                                            batch,\n",
        "                                                            loss))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "    print ('Time for epoch {} sec\\n'.format(time.time() - start))\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.6474\n",
            "Epoch 1 Batch 100 Loss 1.4720\n",
            "Epoch 1 Batch 200 Loss 1.2562\n",
            "Epoch 1 Loss 1.2368\n",
            "Time for epoch 196.85497999191284 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.2186\n",
            "Epoch 2 Batch 100 Loss 1.1867\n",
            "Epoch 2 Batch 200 Loss 1.1829\n",
            "Epoch 2 Loss 1.1333\n",
            "Time for epoch 200.2735607624054 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1231\n",
            "Epoch 3 Batch 100 Loss 1.1599\n",
            "Epoch 3 Batch 200 Loss 1.0567\n",
            "Epoch 3 Loss 1.0716\n",
            "Time for epoch 196.76227521896362 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1003\n",
            "Epoch 4 Batch 100 Loss 1.1212\n",
            "Epoch 4 Batch 200 Loss 1.1072\n",
            "Epoch 4 Loss 1.0543\n",
            "Time for epoch 198.79552221298218 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.0563\n",
            "Epoch 5 Batch 100 Loss 1.0490\n",
            "Epoch 5 Batch 200 Loss 1.0689\n",
            "Epoch 5 Loss 1.0639\n",
            "Time for epoch 198.47851872444153 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.9957\n",
            "Epoch 6 Batch 100 Loss 1.0239\n",
            "Epoch 6 Batch 200 Loss 1.0083\n",
            "Epoch 6 Loss 0.9770\n",
            "Time for epoch 197.65642762184143 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.0136\n",
            "Epoch 7 Batch 100 Loss 1.0148\n",
            "Epoch 7 Batch 200 Loss 0.9730\n",
            "Epoch 7 Loss 0.9976\n",
            "Time for epoch 200.26993584632874 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.9698\n",
            "Epoch 8 Batch 100 Loss 0.9917\n",
            "Epoch 8 Batch 200 Loss 1.0463\n",
            "Epoch 8 Loss 0.9743\n",
            "Time for epoch 197.09595894813538 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.9563\n",
            "Epoch 9 Batch 100 Loss 1.0164\n",
            "Epoch 9 Batch 200 Loss 1.0236\n",
            "Epoch 9 Loss 0.9980\n",
            "Time for epoch 199.64076375961304 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.9589\n",
            "Epoch 10 Batch 100 Loss 0.9966\n",
            "Epoch 10 Batch 200 Loss 0.9492\n",
            "Epoch 10 Loss 1.0168\n",
            "Time for epoch 197.66526246070862 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i2RSpMO1fzWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## train another simple model"
      ]
    },
    {
      "metadata": {
        "id": "OvA-ffj-fyqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, units):\n",
        "    super(Model, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.dense1 = tf.keras.layers.Dense(128)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "    self.dense2 = tf.keras.layers.Dense(128)\n",
        "    self.batch = tf.keras.layers.BatchNormalization()\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "  def call(self, x):\n",
        "    embedding = self.embedding(x)\n",
        "    dense1 = self.dense1(embedding)\n",
        "    dropout = self.dropout(dense1)\n",
        "    dense2 = self.dense2(dropout)\n",
        "    batch = self.batch(dense2)\n",
        "    prediction = self.fc(dense2)\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXqbPRnRf-xj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension \n",
        "# Here, this is basically just a trick to avoid having \n",
        "# to one-hot encode the characters\n",
        "# I don't think it will add much otherwise\n",
        "# this would be more useful if we had a much larger vocabulary\n",
        "embedding_dim = 128\n",
        "\n",
        "# Number of RNN units\n",
        "units = 256\n",
        "\n",
        "model = Model(vocab_size, embedding_dim, units)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3nFu0Mef-uv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "# Using sparse_softmax_cross_entropy so that we don't have to create one-hot vectors\n",
        "def loss_function(labels, logits):\n",
        "    return tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jH5vhjIQf-rH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "cf46235d-7353-4117-e657-05dd8dc6973b"
      },
      "cell_type": "code",
      "source": [
        "model.build(tf.TensorShape([BATCH_SIZE, max_length]))\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  4864      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch multiple                  512       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  4902      \n",
            "=================================================================\n",
            "Total params: 43,302\n",
            "Trainable params: 43,046\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GB79x8Wjf-n-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# Checkpoint instance\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nM-rzxmf-i8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        },
        "outputId": "172939eb-4b5c-4773-cfe2-7d1ef58624b0"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    # initializing the hidden state at the start of every epoch\n",
        "    # initally hidden is None\n",
        "    hidden = model.reset_states()\n",
        "    \n",
        "    for (batch, (input_seq, target_seq)) in enumerate(dataset):\n",
        "          with tf.GradientTape() as tape:\n",
        "              predictions = model(input_seq)\n",
        "              loss = loss_function(target_seq, predictions)\n",
        "              \n",
        "          grads = tape.gradient(loss, model.variables)\n",
        "          optimizer.apply_gradients(zip(grads, model.variables))\n",
        "\n",
        "          if batch % 100 == 0:\n",
        "              print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n",
        "                                                            batch,\n",
        "                                                            loss))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "    print ('Time for epoch {} sec\\n'.format(time.time() - start))\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.6351\n",
            "Epoch 1 Batch 100 Loss 1.4340\n",
            "Epoch 1 Batch 200 Loss 1.3039\n",
            "Epoch 1 Loss 1.3744\n",
            "Time for epoch 5.690982103347778 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.3653\n",
            "Epoch 2 Batch 100 Loss 1.3192\n",
            "Epoch 2 Batch 200 Loss 1.3418\n",
            "Epoch 2 Loss 1.3669\n",
            "Time for epoch 5.074668645858765 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.3647\n",
            "Epoch 3 Batch 100 Loss 1.3452\n",
            "Epoch 3 Batch 200 Loss 1.2926\n",
            "Epoch 3 Loss 1.2997\n",
            "Time for epoch 5.049818754196167 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.3707\n",
            "Epoch 4 Batch 100 Loss 1.3586\n",
            "Epoch 4 Batch 200 Loss 1.3793\n",
            "Epoch 4 Loss 1.2710\n",
            "Time for epoch 5.062694787979126 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.3196\n",
            "Epoch 5 Batch 100 Loss 1.2701\n",
            "Epoch 5 Batch 200 Loss 1.2999\n",
            "Epoch 5 Loss 1.2751\n",
            "Time for epoch 4.871114253997803 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.3461\n",
            "Epoch 6 Batch 100 Loss 1.3789\n",
            "Epoch 6 Batch 200 Loss 1.2899\n",
            "Epoch 6 Loss 1.3063\n",
            "Time for epoch 4.8943915367126465 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.3061\n",
            "Epoch 7 Batch 100 Loss 1.3500\n",
            "Epoch 7 Batch 200 Loss 1.3296\n",
            "Epoch 7 Loss 1.3223\n",
            "Time for epoch 4.873367071151733 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.3526\n",
            "Epoch 8 Batch 100 Loss 1.3687\n",
            "Epoch 8 Batch 200 Loss 1.3714\n",
            "Epoch 8 Loss 1.3550\n",
            "Time for epoch 4.804427862167358 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.3201\n",
            "Epoch 9 Batch 100 Loss 1.3180\n",
            "Epoch 9 Batch 200 Loss 1.3505\n",
            "Epoch 9 Loss 1.3181\n",
            "Time for epoch 4.717878818511963 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.2780\n",
            "Epoch 10 Batch 100 Loss 1.2993\n",
            "Epoch 10 Batch 200 Loss 1.3290\n",
            "Epoch 10 Loss 1.3195\n",
            "Time for epoch 4.751309633255005 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B8rQoOyCg5MG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### althouth the complex model has smaller loss, considering the model efficiency, decided to use the simpler model at the end."
      ]
    },
    {
      "metadata": {
        "id": "0U_cmqGP8dwg",
        "colab_type": "code",
        "outputId": "50443822-356f-45f5-85d1-ae032fb20d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     ckpt-5.data-00000-of-00001\n",
            "ckpt-10.data-00000-of-00001  ckpt-5.index\n",
            "ckpt-10.index\t\t     ckpt-6.data-00000-of-00001\n",
            "ckpt-1.data-00000-of-00001   ckpt-6.index\n",
            "ckpt-1.index\t\t     ckpt-7.data-00000-of-00001\n",
            "ckpt-2.data-00000-of-00001   ckpt-7.index\n",
            "ckpt-2.index\t\t     ckpt-8.data-00000-of-00001\n",
            "ckpt-3.data-00000-of-00001   ckpt-8.index\n",
            "ckpt-3.index\t\t     ckpt-9.data-00000-of-00001\n",
            "ckpt-4.data-00000-of-00001   ckpt-9.index\n",
            "ckpt-4.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0K3VLTVT81rt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is a hack to let us use the model with a different \n",
        "# batch size later\n",
        "model = Model(vocab_size, embedding_dim, units)\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Le_MRIFI1tRL",
        "colab_type": "code",
        "outputId": "007c7d0b-68de-4ca0-eee6-67a1570570b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1764
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation step (generating text using the learned model)\n",
        "\n",
        "# Number of characters to generate\n",
        "num_generate = max_length\n",
        "\n",
        "k = 0\n",
        "while k < 5:\n",
        "  # You can change the start string to experiment\n",
        "  start_string = random.choice(string.ascii_lowercase)\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing) \n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 0.5\n",
        "\n",
        "\n",
        "  # Here batch size == 1\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a multinomial distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  generated_color = start_string + ''.join(text_generated).replace('<pad>', '')\n",
        "\n",
        "  parts = generated_color.split()\n",
        "  ## generate only the meaningful outputs\n",
        "  if len(parts) >= 4:\n",
        "    if parts[-3].isdigit() and parts[-2].isdigit() and parts[-1].isdigit():\n",
        "      generated_color = ' '.join(map(str,[parts[0],parts[-3],parts[-2],parts[-1]]))\n",
        "      r = float(parts[-3])\n",
        "      g = float(parts[-2])\n",
        "      b = float(parts[-1])\n",
        "      plt.clf()\n",
        "      _ = plt.imshow([[(r, g, b)]])\n",
        "      _ = plt.axis('off')\n",
        "      _ = plt.title(generated_color, fontsize=18)\n",
        "      plt.show()\n",
        "      k += 1\n",
        "\n",
        " "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFdCAYAAABcnZV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1093305a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFdCAYAAABcnZV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBBUg5L/pZ0F9iynCzQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1092b52390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFdCAYAAABcnZV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFPlfKhbWWB5UXYMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f109328eb70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFdCAYAAABcnZV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFSBEUAFCBBUg5D+z9n9ye1ELVAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1092b52e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFdCAYAAABcnZV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUEFKCKoAEUEFaCIoAIUEVSAIv8LcUD2ulHhwR0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f10934284a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UNA7j6Nta9Y3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}