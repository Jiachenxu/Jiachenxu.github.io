{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW41.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hXihozv9-wEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## the GitHub website is  https://Jiachenxu.github.io"
      ]
    },
    {
      "metadata": {
        "id": "e1cDMWdOjJ2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser."
      ]
    },
    {
      "metadata": {
        "id": "248xIjNGCRU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Configure this notebook to work with your GitHub account by populating these fields."
      ]
    },
    {
      "metadata": {
        "id": "Ft9uEY7UCH46",
        "colab_type": "code",
        "outputId": "2b654442-8242-4013-c5b0-87f88ff467b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/d3/f534d1d042465e0e66a04b0fa31dc1f13cfea7d8340017ef4cd649b9c3a0/tensorflowjs-0.6.7-py3-none-any.whl\n",
            "Collecting keras==2.2.2 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 17.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 23.0MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.1.1->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.1.1->tensorflowjs) (40.6.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, keras-preprocessing, keras, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: Keras-Applications 1.0.6\n",
            "    Uninstalling Keras-Applications-1.0.6:\n",
            "      Successfully uninstalled Keras-Applications-1.0.6\n",
            "  Found existing installation: Keras-Preprocessing 1.0.5\n",
            "    Uninstalling Keras-Preprocessing-1.0.5:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.15.1 tensorflowjs-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mYrYFulpzCVq",
        "colab_type": "code",
        "outputId": "75cd35f5-bd65-468c-d935-cb0f5f31d5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install BeautifulSoup4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "klN6WGaMzycy",
        "colab_type": "code",
        "outputId": "155b23a1-97d7-4299-ce11-cc26b5abc67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "1bfgPpKP0g9w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the three books I selected are 'pride and prejudice','Heart of Darkness', \n",
        "# and 'Dracula'\n",
        "quote_page = ['https://www.gutenberg.org/files/1342/1342-0.txt','https://www.gutenberg.org/files/219/219-0.txt','http://www.gutenberg.org/cache/epub/345/pg345.txt']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77IPbknM5_aR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_data(webs):\n",
        "  train = []\n",
        "  label = []\n",
        "  for i in range(len(webs)):\n",
        "    # open the website and parse the web\n",
        "    page = urllib.request.urlopen(webs[i])\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    data = soup.text\n",
        "    # split by line to eliminate the special character\n",
        "    data = data.splitlines()\n",
        "    # join the sentence as a large string for sentence tokenizse\n",
        "    data = ''.join(map(str,data))\n",
        "    # use sent_tokenize from nltk to tokenize the sentence\n",
        "    sent_tokenize_list = sent_tokenize(data)\n",
        "    print(len(sent_tokenize_list))\n",
        "    # since the first 1000 sentence are rather meaningless, use the 1000 to\n",
        "    # 2000 sentense as the raw data to train the model.\n",
        "    try:\n",
        "      train.extend(sent_tokenize_list[1000:2000])\n",
        "    except:\n",
        "      print('len is smaller than 1000')\n",
        "      train.extend(sent_tokenize_list[-1000:])\n",
        "    label.extend([i] * 1000)\n",
        "  return train, np.array(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_XKuA53qChQT",
        "colab_type": "code",
        "outputId": "3bec2d7f-e364-4d5a-b783-4a8cee339fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "train, label = train_data(quote_page)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3947\n",
            "2235\n",
            "7743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mknQs0NK50ch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# all the three books I selected are longer than 2000 sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vxg_T_8rFGXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# shuffle the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIPu3jirFGTq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = list(range(3000))\n",
        "random.shuffle(a)\n",
        "new_train = [train[i] for i in a]\n",
        "new_label = [label[i] for i in a]\n",
        "new_label = np.array(new_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ktq2vVqfFGIY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## split the train and test data set\n",
        "train = new_train[:int(len(new_train)*0.8)]\n",
        "train_lab = new_label[:int(len(new_label)*0.8)]\n",
        "\n",
        "test = new_train[int(len(new_train)*0.8):]\n",
        "test_lab = new_label[int(len(new_label)*0.8):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uweYA2ph8T6J",
        "colab_type": "code",
        "outputId": "06cdf21d-77b7-45f5-f766-72f764e081bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train), len(test), len(new_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 600, 3000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "o4aQBqjV-UUs",
        "colab_type": "code",
        "outputId": "e6fec810-639e-409c-b536-d1690d4e201c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_lab.shape), print(test_lab.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400,)\n",
            "(600,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "g4k9_Ke9CaOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your github username\n",
        "USER_NAME = \"Jiachenxu\" \n",
        "\n",
        "# the email associated with your commits\n",
        "# (may not matter if you leave it as this)\n",
        "USER_EMAIL = \"jx2318@columbia.edu\" \n",
        "\n",
        "# the user token you've created (see the lecture 8 slides for instructions)\n",
        "TOKEN = \"2ffdf9d5f886846d899464c9972ab05c769eb337\" \n",
        "\n",
        "# site name\n",
        "# for example, if my user_name is \"foo\", then this notebook will create\n",
        "# a site at https://foo.github.io/hw4/\n",
        "SITE_NAME = \"hw4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnPqmO8vDDwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, run this cell to configure git."
      ]
    },
    {
      "metadata": {
        "id": "Q0IMoqVdCIb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYfDxuMfDVas",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."
      ]
    },
    {
      "metadata": {
        "id": "qRUyZiFqDUxt",
        "colab_type": "code",
        "outputId": "e3baad76-6383-4850-ce02-4a84e996eed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = USER_NAME + '.github.io'\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Jiachenxu.github.io'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 64 (delta 14), reused 38 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (64/64), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qu4OA27iDU0e",
        "colab_type": "code",
        "outputId": "f42feef7-66fc-4dd3-d897-47cee76f4a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "os.chdir(repo_path)\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KgISB_cAHPIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a folder for your site."
      ]
    },
    {
      "metadata": {
        "id": "UAA6t4slF0nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
        "if not os.path.exists(project_path): \n",
        "  os.mkdir(project_path)\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwYh8sXKHs3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These paths will be used by the converter script."
      ]
    },
    {
      "metadata": {
        "id": "ABggwdWMGe2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJpu2BkSUWe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"
      ]
    },
    {
      "metadata": {
        "id": "CASpAIgJalTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = train\n",
        "y_train = train_lab.reshape(-1,1) # Indicating which book each sentence is from"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVfStwZCYBAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize the documents, create a word index (word -> number)."
      ]
    },
    {
      "metadata": {
        "id": "HOHTxREVQalF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len = 50\n",
        "num_words = 100000\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "feIAyrrxYFoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's how we vectorize a document."
      ]
    },
    {
      "metadata": {
        "id": "4nylzwZpAXR5",
        "colab_type": "code",
        "outputId": "8a1550e0-6eef-4b2d-aa0f-a80d410255e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I could only tell him that I was thehappiest woman in all the wide world, and that I had nothing to give himexcept myself, my life, and my trust, and that with these went my loveand duty for all the days of my life.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "Jfi7tJbHTwIc",
        "colab_type": "code",
        "outputId": "077d3ca4-4967-4715-d4d3-4d6de1ac5e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "vectorized = t.texts_to_sequences([train[0]])\n",
        "print(vectorized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5, 40, 70, 169, 27, 11, 5, 8, 3331, 451, 7, 30, 1, 731, 353, 2, 11, 5, 13, 129, 3, 170, 3332, 133, 26, 213, 2, 26, 666, 2, 11, 17, 150, 142, 26, 3333, 405, 19, 30, 1, 288, 4, 26, 213]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vUfL6MVhYHof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply padding if necessary."
      ]
    },
    {
      "metadata": {
        "id": "rbghRbY5QaMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xwd6ND_UIKk",
        "colab_type": "code",
        "outputId": "fc49d929-1bf1-4929-dcdb-ceb9be6a8ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print(padded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   5   40   70  169   27   11    5    8 3331  451    7   30    1  731\n",
            "   353    2   11    5   13  129    3  170 3332  133   26  213    2   26\n",
            "   666    2   11   17  150  142   26 3333  405   19   30    1  288    4\n",
            "    26  213    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKgvsR8Q9xAY",
        "colab_type": "code",
        "outputId": "9b28b0aa-f63f-4270-ddc4-b2f5faac7da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(t.word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C9NUXTTuYLZ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."
      ]
    },
    {
      "metadata": {
        "id": "UpzusXHhULBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l57eA3ApZGsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a model."
      ]
    },
    {
      "metadata": {
        "id": "oLQeTh3uVqtj",
        "colab_type": "code",
        "outputId": "20070ab5-2ccf-4c15-c5b2-fb71fa1c7126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 20\n",
        "n_classes = 3\n",
        "epochs = 10\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(keras.layers.LSTM(128, return_sequences = True))\n",
        "model.add(keras.layers.LSTM(64))\n",
        "model.add(keras.layers.Dense(128, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 50, 20)            2000000   \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 50, 128)           76288     \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 2,134,403\n",
            "Trainable params: 2,134,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6VOtCRJiYWZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare some training data."
      ]
    },
    {
      "metadata": {
        "id": "-Q8Y1ZuZYYKC",
        "colab_type": "code",
        "outputId": "af386a64-eeb6-4744-81a2-ee64ae30c7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VUWlD3jiX10c",
        "colab_type": "code",
        "outputId": "bd76f197-c71b-4ecb-b403-2ef09081ce43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "cell_type": "code",
      "source": [
        "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=3, \n",
        "                          verbose=1, mode='auto')\n",
        "callbacks_list = [earlystop]\n",
        "model.fit(x_train, y_train, epochs=epochs, validation_split = 0.2, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1920 samples, validate on 480 samples\n",
            "Epoch 1/10\n",
            "1920/1920 [==============================] - 20s 10ms/step - loss: 1.0793 - acc: 0.3979 - val_loss: 1.0200 - val_acc: 0.4708\n",
            "Epoch 2/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.8413 - acc: 0.5714 - val_loss: 0.7801 - val_acc: 0.6083\n",
            "Epoch 3/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.6823 - acc: 0.6578 - val_loss: 0.7866 - val_acc: 0.5771\n",
            "Epoch 4/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.5110 - acc: 0.7490 - val_loss: 0.7546 - val_acc: 0.6854\n",
            "Epoch 5/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.3734 - acc: 0.8557 - val_loss: 0.8801 - val_acc: 0.6750\n",
            "Epoch 6/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.2706 - acc: 0.9115 - val_loss: 1.0038 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.2004 - acc: 0.9370 - val_loss: 1.3431 - val_acc: 0.6958\n",
            "Epoch 8/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.1748 - acc: 0.9490 - val_loss: 1.1847 - val_acc: 0.6687\n",
            "Epoch 9/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.2014 - acc: 0.9396 - val_loss: 1.3240 - val_acc: 0.6646\n",
            "Epoch 10/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.2235 - acc: 0.9318 - val_loss: 1.0752 - val_acc: 0.6708\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2145f83be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "y1YbPNWIenE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## find that the model overfit the data set, so considering simplify the model."
      ]
    },
    {
      "metadata": {
        "id": "Cz8_3mHA_gsf",
        "colab_type": "code",
        "outputId": "e00097bc-2112-4ce7-f571-8944703de513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 20\n",
        "n_classes = 3\n",
        "epochs = 10\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(keras.layers.LSTM(64, return_sequences = True))\n",
        "model.add(keras.layers.LSTM(64))\n",
        "model.add(keras.layers.Dense(64, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 50, 20)            2000000   \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 50, 64)            21760     \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 2,059,139\n",
            "Trainable params: 2,059,139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gQOkju5V_n_p",
        "colab_type": "code",
        "outputId": "11043ad5-04a9-426f-8fe3-f1d8758cdfd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "cell_type": "code",
      "source": [
        "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=3, \n",
        "                          verbose=1, mode='auto')\n",
        "callbacks_list = [earlystop]\n",
        "model.fit(x_train, y_train, epochs=epochs, validation_split = 0.2, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1920 samples, validate on 480 samples\n",
            "Epoch 1/10\n",
            "1920/1920 [==============================] - 20s 10ms/step - loss: 1.0921 - acc: 0.3615 - val_loss: 1.0570 - val_acc: 0.4167\n",
            "Epoch 2/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.9345 - acc: 0.5083 - val_loss: 0.7798 - val_acc: 0.6104\n",
            "Epoch 3/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.6823 - acc: 0.6161 - val_loss: 0.7012 - val_acc: 0.6146\n",
            "Epoch 4/10\n",
            "1920/1920 [==============================] - 18s 9ms/step - loss: 0.5628 - acc: 0.6583 - val_loss: 0.7318 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.5014 - acc: 0.7578 - val_loss: 0.7619 - val_acc: 0.6708\n",
            "Epoch 6/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.3761 - acc: 0.8536 - val_loss: 0.9335 - val_acc: 0.5917\n",
            "Epoch 7/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.3614 - acc: 0.8714 - val_loss: 0.8371 - val_acc: 0.6729\n",
            "Epoch 8/10\n",
            "1920/1920 [==============================] - 17s 9ms/step - loss: 0.2964 - acc: 0.9094 - val_loss: 0.9880 - val_acc: 0.6417\n",
            "Epoch 9/10\n",
            "1920/1920 [==============================] - 18s 9ms/step - loss: 0.2656 - acc: 0.9120 - val_loss: 0.9477 - val_acc: 0.6646\n",
            "Epoch 10/10\n",
            "1920/1920 [==============================] - 18s 9ms/step - loss: 0.2101 - acc: 0.9365 - val_loss: 0.9359 - val_acc: 0.6667\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2145318cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "XWVr-cuN_zhO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### retrain the whole model with the better model"
      ]
    },
    {
      "metadata": {
        "id": "Zwe6-n7e_ykx",
        "colab_type": "code",
        "outputId": "8e6ca56c-60ca-4e82-98a3-e568cabdd9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 20\n",
        "n_classes = 3\n",
        "epochs = 10\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(keras.layers.LSTM(128, return_sequences = True))\n",
        "model.add(keras.layers.LSTM(64))\n",
        "model.add(keras.layers.Dense(128, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train, epochs=epochs, validation_split = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 50, 20)            2000000   \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 50, 128)           76288     \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 2,134,403\n",
            "Trainable params: 2,134,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 23s 9ms/step - loss: 1.0784 - acc: 0.3896\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.9059 - acc: 0.5267\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.6757 - acc: 0.6200\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.5870 - acc: 0.6533\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.5561 - acc: 0.6604\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.5078 - acc: 0.7262\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.4764 - acc: 0.7808\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.2950 - acc: 0.8958\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.2213 - acc: 0.9208\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 20s 8ms/step - loss: 0.1642 - acc: 0.9442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2142020668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "U09xZay3Ajv-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  test the model on the test dataset"
      ]
    },
    {
      "metadata": {
        "id": "7natV6P3Ait6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = t.texts_to_sequences(test)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "y_test = test_lab.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9dsZSQnrqoU",
        "colab_type": "code",
        "outputId": "b9db58d8-c3c2-42b0-9297-d33a2f414f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600/600 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eKR4tf38BWRb",
        "colab_type": "code",
        "outputId": "daa7ade8-570f-4999-9f90-a7a9df8e2191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print('the test loss is:', score[0])\n",
        "print('the test accuracy is:',score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the test loss is: 1.2547202094395955\n",
            "the test accuracy is: 0.6766666642824809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G-Kuwvqcfptq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the model"
      ]
    },
    {
      "metadata": {
        "id": "nyo2Q_ehe2RT",
        "colab_type": "code",
        "outputId": "0835ac6c-785e-42b7-c6e9-7af5c7745e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model artifcats in directory: /content/Jiachenxu.github.io/hw4/model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z609mw1aj-RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Write an index.html and an index.js file configured to load our model."
      ]
    },
    {
      "metadata": {
        "id": "IoFAxt8nj9fp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    Title\n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <select id=\"example-select\" class=\"form-control\">\n",
        "      <option value=\"example1\">Alice's Adventures in Wonderland</option>\n",
        "      <option value=\"example2\">Dracula</option>\n",
        "      <option value=\"example3\">The Iliad</option>\n",
        "    </select>\n",
        "  </div>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JsQLbLnkhhk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_js = \"\"\"\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "const examples = {\n",
        "  'example1':\n",
        "      'Alice was beginning to get very tired of sitting by her sister on the bank.',\n",
        "  'example2':\n",
        "      'Buda-Pesth seems a wonderful place.',\n",
        "  'example3':\n",
        "      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.'      \n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  score_string = \"Class scores: \";\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbvVVh1rkmga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0YtvaoazkuRT",
        "colab_type": "code",
        "outputId": "f70a3195-b7ec-418e-971c-ffbbdab678ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index.html  index.js  model_js\tpython\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3NX9FVLiBO7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Commit and push everything. Note: we're storing large binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."
      ]
    },
    {
      "metadata": {
        "id": "RoL5aoRUh5DB",
        "colab_type": "code",
        "outputId": "4b00e91c-e544-4ad8-88ab-a251b31ef298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "!git add . \n",
        "!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master bbc42f5] colab -> github\n",
            " 5 files changed, 2 insertions(+), 2 deletions(-)\n",
            " create mode 100644 hw4/model_js/group1-shard1of3\n",
            " create mode 100644 hw4/model_js/group1-shard2of3\n",
            " create mode 100644 hw4/model_js/group1-shard3of3\n",
            " rewrite hw4/model_js/metadata.json (97%)\n",
            " rewrite hw4/model_js/model.json (94%)\n",
            "remote: Invalid username or password.\n",
            "fatal: Authentication failed for 'https://Jiachenxu:2ffdf9d5f886846d899464c9972ab05c769eb337@github.com/Jiachenxu/Jiachenxu.github.io/'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WDoo_fDVic2E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."
      ]
    },
    {
      "metadata": {
        "id": "1V1QLCxlikOI",
        "colab_type": "code",
        "outputId": "73f7703d-4f06-49c6-9e14-455b030a3c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, visit https://Jiachenxu.github.io/hw4/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mnN6zAHWqPnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
      ]
    },
    {
      "metadata": {
        "id": "PkDydtmwB38z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfKe0dQj-szw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}